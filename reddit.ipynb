{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Span-ASTE' already exists and is not an empty directory.\n",
      "HEAD is now at 7cbf035 Add SpanModel with scikit-learn-style methods for easy usage (fit, predict, score)\n",
      "Requirement already satisfied: Cython==0.29.21 in /home/lqx/.local/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (0.29.21)\n",
      "Requirement already satisfied: PYEVALB==0.1.3 in /home/lqx/.local/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.1.3)\n",
      "Requirement already satisfied: allennlp-models==1.2.2 in /home/lqx/.local/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.2.2)\n",
      "Requirement already satisfied: allennlp==1.2.2 in /home/lqx/.local/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.2.2)\n",
      "Requirement already satisfied: botocore==1.19.46 in /home/lqx/.local/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.19.46)\n",
      "Requirement already satisfied: fire==0.3.1 in /home/lqx/.local/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (0.3.1)\n",
      "Requirement already satisfied: nltk==3.6.6 in /home/lqx/.local/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (3.6.6)\n",
      "Requirement already satisfied: numpy==1.21.5 in /home/lqx/.local/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.21.5)\n",
      "Requirement already satisfied: pandas==1.1.5 in /home/lqx/.local/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (1.1.5)\n",
      "Requirement already satisfied: pydantic==1.6.2 in /home/lqx/.local/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (1.6.2)\n",
      "Requirement already satisfied: scikit-learn==0.22.2.post1 in /home/lqx/.local/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (0.22.2.post1)\n",
      "Requirement already satisfied: torch==1.7.0 in /home/lqx/.local/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (1.7.0)\n",
      "Requirement already satisfied: torchvision==0.8.1 in /home/lqx/.local/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (0.8.1)\n",
      "Requirement already satisfied: transformers==3.4.0 in /home/lqx/.local/lib/python3.8/site-packages (from -r requirements.txt (line 14)) (3.4.0)\n",
      "Requirement already satisfied: pytablewriter>=0.10.2 in /home/lqx/.local/lib/python3.8/site-packages (from PYEVALB==0.1.3->-r requirements.txt (line 2)) (0.64.2)\n",
      "Requirement already satisfied: word2number>=1.1 in /home/lqx/.local/lib/python3.8/site-packages (from allennlp-models==1.2.2->-r requirements.txt (line 3)) (1.1)\n",
      "Requirement already satisfied: conllu==4.2.1 in /home/lqx/.local/lib/python3.8/site-packages (from allennlp-models==1.2.2->-r requirements.txt (line 3)) (4.2.1)\n",
      "Requirement already satisfied: py-rouge==1.1 in /home/lqx/.local/lib/python3.8/site-packages (from allennlp-models==1.2.2->-r requirements.txt (line 3)) (1.1)\n",
      "Requirement already satisfied: ftfy in /home/lqx/.local/lib/python3.8/site-packages (from allennlp-models==1.2.2->-r requirements.txt (line 3)) (6.1.1)\n",
      "Requirement already satisfied: pytest in /home/lqx/.local/lib/python3.8/site-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (7.1.2)\n",
      "Requirement already satisfied: overrides==3.1.0 in /home/lqx/.local/lib/python3.8/site-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: filelock<3.1,>=3.0 in /home/lqx/.local/lib/python3.8/site-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (3.0.12)\n",
      "Requirement already satisfied: boto3<2.0,>=1.14 in /home/lqx/.local/lib/python3.8/site-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (1.20.21)\n",
      "Requirement already satisfied: h5py in /home/lqx/.local/lib/python3.8/site-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (3.7.0)\n",
      "Requirement already satisfied: tensorboardX>=1.2 in /home/lqx/.local/lib/python3.8/site-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (2.5.1)\n",
      "Requirement already satisfied: spacy<2.4,>=2.1.0 in /home/lqx/.local/lib/python3.8/site-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (2.3.7)\n",
      "Requirement already satisfied: scipy in /home/lqx/.local/lib/python3.8/site-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (1.7.1)\n",
      "Requirement already satisfied: jsonpickle in /home/lqx/.local/lib/python3.8/site-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (2.2.0)\n",
      "Requirement already satisfied: jsonnet>=0.10.0; sys_platform != \"win32\" in /home/lqx/.local/lib/python3.8/site-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.19 in /home/lqx/.local/lib/python3.8/site-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (4.62.3)\n",
      "Requirement already satisfied: requests>=2.18 in /usr/lib/python3/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (2.22.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/lqx/.local/lib/python3.8/site-packages (from botocore==1.19.46->-r requirements.txt (line 5)) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/lib/python3/dist-packages (from botocore==1.19.46->-r requirements.txt (line 5)) (2.7.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4; python_version != \"3.4\" in /usr/lib/python3/dist-packages (from botocore==1.19.46->-r requirements.txt (line 5)) (1.25.8)\n",
      "Requirement already satisfied: termcolor in /home/lqx/.local/lib/python3.8/site-packages (from fire==0.3.1->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from fire==0.3.1->-r requirements.txt (line 6)) (1.14.0)\n",
      "Requirement already satisfied: click in /home/lqx/.local/lib/python3.8/site-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/lqx/.local/lib/python3.8/site-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/lqx/.local/lib/python3.8/site-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (2021.11.10)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/lib/python3/dist-packages (from pandas==1.1.5->-r requirements.txt (line 9)) (2019.3)\n",
      "Requirement already satisfied: future in /usr/lib/python3/dist-packages (from torch==1.7.0->-r requirements.txt (line 12)) (0.18.2)\n",
      "Requirement already satisfied: typing-extensions in /home/lqx/.local/lib/python3.8/site-packages (from torch==1.7.0->-r requirements.txt (line 12)) (3.10.0.2)\n",
      "Collecting dataclasses\n",
      "  Using cached dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/lib/python3/dist-packages (from torchvision==0.8.1->-r requirements.txt (line 13)) (7.0.0)\n",
      "Requirement already satisfied: protobuf in /home/lqx/.local/lib/python3.8/site-packages (from transformers==3.4.0->-r requirements.txt (line 14)) (3.20.1)\n",
      "Requirement already satisfied: packaging in /home/lqx/.local/lib/python3.8/site-packages (from transformers==3.4.0->-r requirements.txt (line 14)) (21.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /home/lqx/.local/lib/python3.8/site-packages (from transformers==3.4.0->-r requirements.txt (line 14)) (0.1.96)\n",
      "Requirement already satisfied: sacremoses in /home/lqx/.local/lib/python3.8/site-packages (from transformers==3.4.0->-r requirements.txt (line 14)) (0.0.53)\n",
      "Requirement already satisfied: tokenizers==0.9.2 in /home/lqx/.local/lib/python3.8/site-packages (from transformers==3.4.0->-r requirements.txt (line 14)) (0.9.2)\n",
      "Requirement already satisfied: DataProperty<2,>=0.55.0 in /home/lqx/.local/lib/python3.8/site-packages (from pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (0.55.0)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.0 in /home/lqx/.local/lib/python3.8/site-packages (from pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /usr/lib/python3/dist-packages (from pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (45.2.0)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /home/lqx/.local/lib/python3.8/site-packages (from pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /home/lqx/.local/lib/python3.8/site-packages (from pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (0.1.2)\n",
      "Requirement already satisfied: typepy[datetime]<2,>=1.2.0 in /home/lqx/.local/lib/python3.8/site-packages (from pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: pathvalidate<3,>=2.3.0 in /home/lqx/.local/lib/python3.8/site-packages (from pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (2.5.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /home/lqx/.local/lib/python3.8/site-packages (from ftfy->allennlp-models==1.2.2->-r requirements.txt (line 3)) (0.2.5)\n",
      "Requirement already satisfied: iniconfig in /home/lqx/.local/lib/python3.8/site-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/lqx/.local/lib/python3.8/site-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/lqx/.local/lib/python3.8/site-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (2.0.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/lqx/.local/lib/python3.8/site-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (21.4.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /home/lqx/.local/lib/python3.8/site-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (1.11.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/lqx/.local/lib/python3.8/site-packages (from boto3<2.0,>=1.14->allennlp==1.2.2->-r requirements.txt (line 4)) (0.5.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/lqx/.local/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/lqx/.local/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (0.7.5)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/lqx/.local/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (7.4.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/lqx/.local/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/lqx/.local/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (0.8.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/lqx/.local/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/lqx/.local/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/lqx/.local/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (1.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/lqx/.local/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (3.0.6)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers==3.4.0->-r requirements.txt (line 14)) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.4 in /usr/lib/python3/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (3.0.4)\n",
      "\u001b[31mERROR: fairscale 0.4.6 has requirement torch>=1.8.0, but you'll have torch 1.7.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: dataclasses\n",
      "Successfully installed dataclasses-0.6\n",
      "Found existing installation: dataclasses 0.6\n",
      "Uninstalling dataclasses-0.6:\n",
      "  Successfully uninstalled dataclasses-0.6\n",
      "Archive:  data.zip\n",
      "--2022-06-08 02:41:45--  https://github.com/chiayewken/Span-ASTE/releases/download/v1.0.0/pretrained_14lap.tar\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/371216048/7cc1d21a-b509-4c64-a3ea-ed04f6d5639c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220607%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220607T184146Z&X-Amz-Expires=300&X-Amz-Signature=6af17a4dfdb78f71aca9abe2975a258c981046841f9233d064d2b139715f97c0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=371216048&response-content-disposition=attachment%3B%20filename%3Dpretrained_14lap.tar&response-content-type=application%2Foctet-stream [following]\n",
      "--2022-06-08 02:41:46--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/371216048/7cc1d21a-b509-4c64-a3ea-ed04f6d5639c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220607%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220607T184146Z&X-Amz-Expires=300&X-Amz-Signature=6af17a4dfdb78f71aca9abe2975a258c981046841f9233d064d2b139715f97c0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=371216048&response-content-disposition=attachment%3B%20filename%3Dpretrained_14lap.tar&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 408453120 (390M) [application/octet-stream]\n",
      "Saving to: ‘pretrained_14lap.tar.1’\n",
      "\n",
      "pretrained_14lap.ta 100%[===================>] 389.53M  4.61MB/s    in 78s     \n",
      "\n",
      "2022-06-08 02:43:05 (4.98 MB/s) - ‘pretrained_14lap.tar.1’ saved [408453120/408453120]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/chiayewken/Span-ASTE.git\n",
    "!cd Span-ASTE && git checkout 7cbf035\n",
    "!cp -a Span-ASTE/* .\n",
    "!bash setup.sh\n",
    "!wget https://github.com/chiayewken/Span-ASTE/releases/download/v1.0.0/pretrained_14lap.tar\n",
    "!tar -xf pretrained_14lap.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_path = 'aste/data/triplet_data/reddit01/'\n",
    "post_path = topic_path+'submissions'\n",
    "comments_path = topic_path+'comments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iajghl4</td>\n",
       "      <td>v0yimw</td>\n",
       "      <td>politicians hate him, this one easy trick to e...</td>\n",
       "      <td>1653915731</td>\n",
       "      <td>t3_v0yimw</td>\n",
       "      <td>/r/singapore/comments/v0yimw/new_ability_tests...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iajo48p</td>\n",
       "      <td>v0yimw</td>\n",
       "      <td>Thats an interesting way of saying that you ar...</td>\n",
       "      <td>1653919785</td>\n",
       "      <td>t3_v0yimw</td>\n",
       "      <td>/r/singapore/comments/v0yimw/new_ability_tests...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iajslfk</td>\n",
       "      <td>v0yimw</td>\n",
       "      <td>The govt can put them in whatever role they wa...</td>\n",
       "      <td>1653921939</td>\n",
       "      <td>t3_v0yimw</td>\n",
       "      <td>/r/singapore/comments/v0yimw/new_ability_tests...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ialjw3b</td>\n",
       "      <td>v0yimw</td>\n",
       "      <td>When you have no operational requirement for p...</td>\n",
       "      <td>1653951399</td>\n",
       "      <td>t3_v0yimw</td>\n",
       "      <td>/r/singapore/comments/v0yimw/new_ability_tests...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iaje9kl</td>\n",
       "      <td>v0yimw</td>\n",
       "      <td>Sure you can shift the goalpost. But if the mo...</td>\n",
       "      <td>1653914432</td>\n",
       "      <td>t3_v0yimw</td>\n",
       "      <td>/r/singapore/comments/v0yimw/new_ability_tests...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4806</th>\n",
       "      <td>iafztbs</td>\n",
       "      <td>v0do9s</td>\n",
       "      <td>So what</td>\n",
       "      <td>1653842509</td>\n",
       "      <td>t3_v0do9s</td>\n",
       "      <td>/r/singapore/comments/v0do9s/weekonweek_infect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4807</th>\n",
       "      <td>iahr5yd</td>\n",
       "      <td>v0do9s</td>\n",
       "      <td>MMTF still needs 3 more years of data to meet ...</td>\n",
       "      <td>1653873570</td>\n",
       "      <td>t3_v0do9s</td>\n",
       "      <td>/r/singapore/comments/v0do9s/weekonweek_infect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4808</th>\n",
       "      <td>ian007a</td>\n",
       "      <td>v0do9s</td>\n",
       "      <td>I don’t even know what the average case number...</td>\n",
       "      <td>1653982976</td>\n",
       "      <td>t3_v0do9s</td>\n",
       "      <td>/r/singapore/comments/v0do9s/weekonweek_infect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>iaht7e6</td>\n",
       "      <td>v0do9s</td>\n",
       "      <td>Please! They're already optional at work and t...</td>\n",
       "      <td>1653874622</td>\n",
       "      <td>t1_iahn2we</td>\n",
       "      <td>/r/singapore/comments/v0do9s/weekonweek_infect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4810</th>\n",
       "      <td>iahye3a</td>\n",
       "      <td>v0do9s</td>\n",
       "      <td>Can just remove la.\\n\\nNo difference since maj...</td>\n",
       "      <td>1653877263</td>\n",
       "      <td>t1_iahn2we</td>\n",
       "      <td>/r/singapore/comments/v0do9s/weekonweek_infect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4811 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id submission_id  \\\n",
       "0     iajghl4        v0yimw   \n",
       "1     iajo48p        v0yimw   \n",
       "2     iajslfk        v0yimw   \n",
       "3     ialjw3b        v0yimw   \n",
       "4     iaje9kl        v0yimw   \n",
       "...       ...           ...   \n",
       "4806  iafztbs        v0do9s   \n",
       "4807  iahr5yd        v0do9s   \n",
       "4808  ian007a        v0do9s   \n",
       "4809  iaht7e6        v0do9s   \n",
       "4810  iahye3a        v0do9s   \n",
       "\n",
       "                                                   body  created_utc  \\\n",
       "0     politicians hate him, this one easy trick to e...   1653915731   \n",
       "1     Thats an interesting way of saying that you ar...   1653919785   \n",
       "2     The govt can put them in whatever role they wa...   1653921939   \n",
       "3     When you have no operational requirement for p...   1653951399   \n",
       "4     Sure you can shift the goalpost. But if the mo...   1653914432   \n",
       "...                                                 ...          ...   \n",
       "4806                                            So what   1653842509   \n",
       "4807  MMTF still needs 3 more years of data to meet ...   1653873570   \n",
       "4808  I don’t even know what the average case number...   1653982976   \n",
       "4809  Please! They're already optional at work and t...   1653874622   \n",
       "4810  Can just remove la.\\n\\nNo difference since maj...   1653877263   \n",
       "\n",
       "       parent_id                                          permalink  \n",
       "0      t3_v0yimw  /r/singapore/comments/v0yimw/new_ability_tests...  \n",
       "1      t3_v0yimw  /r/singapore/comments/v0yimw/new_ability_tests...  \n",
       "2      t3_v0yimw  /r/singapore/comments/v0yimw/new_ability_tests...  \n",
       "3      t3_v0yimw  /r/singapore/comments/v0yimw/new_ability_tests...  \n",
       "4      t3_v0yimw  /r/singapore/comments/v0yimw/new_ability_tests...  \n",
       "...          ...                                                ...  \n",
       "4806   t3_v0do9s  /r/singapore/comments/v0do9s/weekonweek_infect...  \n",
       "4807   t3_v0do9s  /r/singapore/comments/v0do9s/weekonweek_infect...  \n",
       "4808   t3_v0do9s  /r/singapore/comments/v0do9s/weekonweek_infect...  \n",
       "4809  t1_iahn2we  /r/singapore/comments/v0do9s/weekonweek_infect...  \n",
       "4810  t1_iahn2we  /r/singapore/comments/v0do9s/weekonweek_infect...  \n",
       "\n",
       "[4811 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat comments csv under the topic \n",
    "comments = os.path.join(comments_path, '*.csv')\n",
    "comments = glob.glob(comments)\n",
    "comments_df = pd.concat(map(pd.read_csv, comments), ignore_index=True)\n",
    "comments = pd.DataFrame(comments_df.iloc[:,2])\n",
    "comments.to_csv('comments.csv', index=False)\n",
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'command': 'cd /home/lqx/Documents/Capstone/REddit && allennlp predict pretrained_14lap/weights/model.tar.gz /home/lqx/Documents/Capstone/REddit/pretrained_14lap/temp_data/pred_in.json --predictor span_model --include-package span_model --use-dataset-reader  --output-file pretrained_14lap/temp_data/pred_out.json --cuda-device 0 --silent '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "2022-07-15 00:17:06,778 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lqx/.local/bin/allennlp\", line 8, in <module>\n",
      "    sys.exit(run())\n",
      "  File \"/home/lqx/.local/lib/python3.8/site-packages/allennlp/__main__.py\", line 34, in run\n",
      "    main(prog=\"allennlp\")\n",
      "  File \"/home/lqx/.local/lib/python3.8/site-packages/allennlp/commands/__init__.py\", line 118, in main\n",
      "    args.func(args)\n",
      "  File \"/home/lqx/.local/lib/python3.8/site-packages/allennlp/commands/predict.py\", line 205, in _predict\n",
      "    predictor = _get_predictor(args)\n",
      "  File \"/home/lqx/.local/lib/python3.8/site-packages/allennlp/commands/predict.py\", line 105, in _get_predictor\n",
      "    check_for_gpu(args.cuda_device)\n",
      "  File \"/home/lqx/.local/lib/python3.8/site-packages/allennlp/common/checks.py\", line 128, in check_for_gpu\n",
      "    raise ConfigurationError(\n",
      "allennlp.common.checks.ConfigurationError: Experiment specified a GPU but none is available; if you want to run on CPU use the override 'trainer.cuda_device=-1' in the json config file.\n",
      "module 'torch.cuda' has no attribute '_check_driver'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pretrained_14lap/temp_data/pred_out.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10579/1523112410.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'comments.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_10579/1523112410.py\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(model, data_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSplitEnum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_full_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Capstone/REddit/aste/wrapper.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, path_in, path_out)\u001b[0m\n\u001b[1;32m     88\u001b[0m         )\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_temp_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSpanModelPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         data = Data(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pretrained_14lap/temp_data/pred_out.json'"
     ]
    }
   ],
   "source": [
    "# Use pretrained SpanModel weights for prediction\n",
    "import sys\n",
    "sys.path.append(\"aste\")\n",
    "from pathlib import Path\n",
    "from aste.data_utils import Data, Sentence, SplitEnum\n",
    "from aste.wrapper import SpanModel\n",
    "import os\n",
    "\n",
    "model = SpanModel(save_dir=\"pretrained_14lap\", random_seed=0)\n",
    "\n",
    "def prediction(model, data_path):\n",
    "    path_in = os.path.splitext(data_path)[0]+'_in.txt'\n",
    "    path_out = os.path.splitext(data_path)[0]+'_out.txt'\n",
    "    with open(data_path)as f:\n",
    "        texts = f.readlines()\n",
    "        sent = [Sentence(tokens=text.split(), triples=[], pos=[], is_labeled=False, weight=1, id=0) for text in texts]\n",
    "        data = Data(root=Path(), data_split=SplitEnum.test, sentences=sent)\n",
    "        data.save_to_path(path_in)\n",
    "        model.predict(path_in, path_out)\n",
    "        data = Data.load_from_full_path(path_out)\n",
    "    return data.sentences[0]\n",
    "\n",
    "prediction(model, 'comments.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
